# One possible value among: MaxEnt, BiLSTM
[emotionClassifier]
emotionclassifier = MaxEnt

#One possible value among: Bert, Openai-gpt, TransfoXL, None.
[languageModel]
languagemodel = 'Openai-gpt'

#One possible value among: int
[forwardtranslations]   ;(number of source->target translations)
numbforwtransl = 1000

[backtranslation]   ;(number of target->source translations)
numbbacktransl = 3

[n_best]   ;(number of best scoring paraphrases)
top_n = 2

#One possible value among: int, None
[Cluster]   ;(number of translations- selected from forward translations- that will be backtranslated)
cluster= 100    ;(if int, this number needs to be <=numbforwtransl)

#One possible value among: de, en, ru, fr  
[Language]
sourcelanguage = de

#Many possible values (depending on sourcelanguage): 
#   sourceLanguage            targetLanguage
#        en                     de, ru  
#     de, ru                      en
[TargetLanguages]
targetlanguage = de, ru

# One of the following: Sampling, Beamsearch
[Decoding]
decoding=Sampling

# One of the following: Simple_Overgeneration, Simple_translation, Restore_Overgeneration
# The first is to look for emotion variations into the overgenerated paraprhases
# The second is to take the translation spontaneouly produced by fairseq, and analyse its emotion connotation
# The third takes the paraphrase with min delta

[Goal]
goal= Simple_translation

